{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Kiểm tra GPU được cấp phát</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "BQNLZ86t9R3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "GOVtzLUjjZ1W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815d4888-318b-4f0d-88e7-6cb415e80242"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep 26 01:16:51 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Cài đặt bổ sung một số thư viện</h3>\n",
        "</div>\n",
        "Nền tảng Google Colab cung cấp môi trường với các thư viện Machine Learning, Deep Learning cơ bản đã được cài đặt sẵn, phần này sẽ cài đặt một số thư viện sử dụng thêm."
      ],
      "metadata": {
        "id": "vigGQG1--GdX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tChf3YMRYr4m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54844fa7-f545-4cb8-a0af-ca51255c7033"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.8.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n",
            "Collecting segmentation_models_pytorch\n",
            "  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (11.3.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.6.2)\n",
            "Requirement already satisfied: timm>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (1.0.19)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (0.23.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from segmentation_models_pytorch) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (1.1.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8->segmentation_models_pytorch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2025.8.3)\n",
            "Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: segmentation_models_pytorch\n",
            "Successfully installed segmentation_models_pytorch-0.5.0\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.16.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.11.9)\n",
            "Requirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.0.11)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install segmentation_models_pytorch\n",
        "!pip install albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Download dữ liệu</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "I_K_s-Yk-nKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
        "!wget https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz"
      ],
      "metadata": {
        "id": "mQmfCxYGZaTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf8758a-2349-4152-b654-95c6d1491078"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-26 01:28:19--  https://thor.robots.ox.ac.uk/~vgg/data/pets/images.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 308 Permanent Redirect\n",
            "Location: https://thor.robots.ox.ac.uk/pets/images.tar.gz [following]\n",
            "--2025-09-26 01:28:19--  https://thor.robots.ox.ac.uk/pets/images.tar.gz\n",
            "Reusing existing connection to thor.robots.ox.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 791918971 (755M) [application/octet-stream]\n",
            "Saving to: ‘images.tar.gz’\n",
            "\n",
            "images.tar.gz       100%[===================>] 755.23M  40.2MB/s    in 20s     \n",
            "\n",
            "2025-09-26 01:28:40 (36.9 MB/s) - ‘images.tar.gz’ saved [791918971/791918971]\n",
            "\n",
            "--2025-09-26 01:28:40--  https://thor.robots.ox.ac.uk/~vgg/data/pets/annotations.tar.gz\n",
            "Resolving thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)... 129.67.95.98\n",
            "Connecting to thor.robots.ox.ac.uk (thor.robots.ox.ac.uk)|129.67.95.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 308 Permanent Redirect\n",
            "Location: https://thor.robots.ox.ac.uk/pets/annotations.tar.gz [following]\n",
            "--2025-09-26 01:28:40--  https://thor.robots.ox.ac.uk/pets/annotations.tar.gz\n",
            "Reusing existing connection to thor.robots.ox.ac.uk:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19173078 (18M) [application/octet-stream]\n",
            "Saving to: ‘annotations.tar.gz’\n",
            "\n",
            "annotations.tar.gz  100%[===================>]  18.28M  17.0MB/s    in 1.1s    \n",
            "\n",
            "2025-09-26 01:28:42 (17.0 MB/s) - ‘annotations.tar.gz’ saved [19173078/19173078]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3></h3>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "7dnqP5oJ-yEs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Giải nén dữ liệu</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "ONGrqXmFCAuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf annotations.tar.gz\n",
        "!tar -xf images.tar.gz"
      ],
      "metadata": {
        "id": "fZ5sutIwZnkA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "id": "f0GrLEX-pt_L",
        "outputId": "be03735a-5db5-46d9-9e68-9e05636f3374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update"
      ],
      "metadata": {
        "id": "1KrQfU9vqZzB",
        "outputId": "428c30c2-a5a4-4566-d7ff-0ce363362f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/129 kB 11%] [Connect\u001b[0m\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [1 InRelease 117 kB/129 \u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [Connected to cloud.r-pr\u001b[0m\r                                                                               \rHit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,371 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,609 kB]\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [81.0 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,808 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,307 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,804 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,690 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,577 kB]\n",
            "Fetched 33.9 MB in 3s (10.5 MB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "38 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt upgrade"
      ],
      "metadata": {
        "id": "tKSARcE5qi05",
        "outputId": "87ce7347-cda5-40b0-ed84-0e27a08f6a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following packages have been kept back:\n",
            "  libcudnn9-cuda-12 libcudnn9-dev-cuda-12 libnccl-dev libnccl2\n",
            "The following packages will be upgraded:\n",
            "  base-files binutils binutils-common binutils-x86-64-linux-gnu\n",
            "  cuda-toolkit-12-config-common cuda-toolkit-config-common dpkg dpkg-dev\n",
            "  e2fsprogs libbinutils libc-bin libcap2 libctf-nobfd0 libctf0 libdpkg-perl\n",
            "  libext2fs2 libgnutls30 libldap-2.5-0 libpam-modules libpam-modules-bin\n",
            "  libpam-runtime libpam0g libperl5.34 libseccomp2 libss2 libtasn1-6 libudev1\n",
            "  linux-libc-dev logsave openssl perl perl-base perl-modules-5.34\n",
            "  python3-pkg-resources\n",
            "34 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 21.7 MB of archives.\n",
            "After this operation, 355 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 base-files amd64 12ubuntu4.7 [61.9 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-12-config-common 12.9.79-1 [16.6 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  cuda-toolkit-config-common 13.0.88-1 [17.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dpkg amd64 1.21.1ubuntu2.6 [1,239 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-pkg-resources all 68.1.2-2~jammy3 [216 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libperl5.34 amd64 5.34.0-3ubuntu1.5 [4,797 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 perl amd64 5.34.0-3ubuntu1.5 [232 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 perl-base amd64 5.34.0-3ubuntu1.5 [1,761 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 perl-modules-5.34 all 5.34.0-3ubuntu1.5 [2,977 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-bin amd64 2.35-0ubuntu3.11 [706 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpam0g amd64 1.4.0-11ubuntu2.6 [59.9 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpam-modules-bin amd64 1.4.0-11ubuntu2.6 [37.4 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpam-modules amd64 1.4.0-11ubuntu2.6 [282 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 logsave amd64 1.46.5-2ubuntu1.2 [10.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libext2fs2 amd64 1.46.5-2ubuntu1.2 [208 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 e2fsprogs amd64 1.46.5-2ubuntu1.2 [590 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libcap2 amd64 1:2.44-1ubuntu0.22.04.2 [18.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpam-runtime all 1.4.0-11ubuntu2.6 [40.2 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtasn1-6 amd64 4.18.0-4ubuntu0.1 [43.5 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgnutls30 amd64 3.7.3-4ubuntu1.7 [967 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libseccomp2 amd64 2.5.3-2ubuntu3~22.04.1 [47.4 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libss2 amd64 1.46.5-2ubuntu1.2 [12.3 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openssl amd64 3.0.2-0ubuntu1.19 [1,186 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf0 amd64 2.38-4ubuntu2.8 [103 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libctf-nobfd0 amd64 2.38-4ubuntu2.8 [108 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-x86-64-linux-gnu amd64 2.38-4ubuntu2.8 [2,324 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libbinutils amd64 2.38-4ubuntu2.8 [661 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils amd64 2.38-4ubuntu2.8 [3,196 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 binutils-common amd64 2.38-4ubuntu2.8 [223 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 dpkg-dev all 1.21.1ubuntu2.6 [922 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libdpkg-perl all 1.21.1ubuntu2.6 [237 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libldap-2.5-0 amd64 2.5.19+dfsg-0ubuntu0.22.04.1 [184 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-libc-dev amd64 5.15.0-156.166 [1,339 kB]\n",
            "Fetched 21.7 MB in 2s (13.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 34.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../base-files_12ubuntu4.7_amd64.deb ...\n",
            "Unpacking base-files (12ubuntu4.7) over (12ubuntu4.6) ...\n",
            "Setting up base-files (12ubuntu4.7) ...\n",
            "Installing new version of config file /etc/issue ...\n",
            "Installing new version of config file /etc/issue.net ...\n",
            "Installing new version of config file /etc/lsb-release ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../dpkg_1.21.1ubuntu2.6_amd64.deb ...\n",
            "Unpacking dpkg (1.21.1ubuntu2.6) over (1.21.1ubuntu2.3) ...\n",
            "Setting up dpkg (1.21.1ubuntu2.6) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libperl5.34_5.34.0-3ubuntu1.5_amd64.deb ...\n",
            "Unpacking libperl5.34:amd64 (5.34.0-3ubuntu1.5) over (5.34.0-3ubuntu1.3) ...\n",
            "Preparing to unpack .../perl_5.34.0-3ubuntu1.5_amd64.deb ...\n",
            "Unpacking perl (5.34.0-3ubuntu1.5) over (5.34.0-3ubuntu1.3) ...\n",
            "Preparing to unpack .../perl-base_5.34.0-3ubuntu1.5_amd64.deb ...\n",
            "Unpacking perl-base (5.34.0-3ubuntu1.5) over (5.34.0-3ubuntu1.3) ...\n",
            "Setting up perl-base (5.34.0-3ubuntu1.5) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../perl-modules-5.34_5.34.0-3ubuntu1.5_all.deb ...\n",
            "Unpacking perl-modules-5.34 (5.34.0-3ubuntu1.5) over (5.34.0-3ubuntu1.3) ...\n",
            "Preparing to unpack .../libc-bin_2.35-0ubuntu3.11_amd64.deb ...\n",
            "Unpacking libc-bin (2.35-0ubuntu3.11) over (2.35-0ubuntu3.8) ...\n",
            "Setting up libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam0g_1.4.0-11ubuntu2.6_amd64.deb ...\n",
            "Unpacking libpam0g:amd64 (1.4.0-11ubuntu2.6) over (1.4.0-11ubuntu2.4) ...\n",
            "Setting up libpam0g:amd64 (1.4.0-11ubuntu2.6) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam-modules-bin_1.4.0-11ubuntu2.6_amd64.deb ...\n",
            "Unpacking libpam-modules-bin (1.4.0-11ubuntu2.6) over (1.4.0-11ubuntu2.4) ...\n",
            "Setting up libpam-modules-bin (1.4.0-11ubuntu2.6) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam-modules_1.4.0-11ubuntu2.6_amd64.deb ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Unpacking libpam-modules:amd64 (1.4.0-11ubuntu2.6) over (1.4.0-11ubuntu2.4) ...\n",
            "Setting up libpam-modules:amd64 (1.4.0-11ubuntu2.6) ...\n",
            "Installing new version of config file /etc/security/namespace.init ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../logsave_1.46.5-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking logsave (1.46.5-2ubuntu1.2) over (1.46.5-2ubuntu1.1) ...\n",
            "Preparing to unpack .../libext2fs2_1.46.5-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libext2fs2:amd64 (1.46.5-2ubuntu1.2) over (1.46.5-2ubuntu1.1) ...\n",
            "Setting up libext2fs2:amd64 (1.46.5-2ubuntu1.2) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../e2fsprogs_1.46.5-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking e2fsprogs (1.46.5-2ubuntu1.2) over (1.46.5-2ubuntu1.1) ...\n",
            "Preparing to unpack .../libcap2_1%3a2.44-1ubuntu0.22.04.2_amd64.deb ...\n",
            "Unpacking libcap2:amd64 (1:2.44-1ubuntu0.22.04.2) over (1:2.44-1ubuntu0.22.04.1) ...\n",
            "Setting up libcap2:amd64 (1:2.44-1ubuntu0.22.04.2) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libpam-runtime_1.4.0-11ubuntu2.6_all.deb ...\n",
            "Unpacking libpam-runtime (1.4.0-11ubuntu2.6) over (1.4.0-11ubuntu2.4) ...\n",
            "Setting up libpam-runtime (1.4.0-11ubuntu2.6) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.16_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.16) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libtasn1-6_4.18.0-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libtasn1-6:amd64 (4.18.0-4ubuntu0.1) over (4.18.0-4build1) ...\n",
            "Setting up libtasn1-6:amd64 (4.18.0-4ubuntu0.1) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libgnutls30_3.7.3-4ubuntu1.7_amd64.deb ...\n",
            "Unpacking libgnutls30:amd64 (3.7.3-4ubuntu1.7) over (3.7.3-4ubuntu1.5) ...\n",
            "Setting up libgnutls30:amd64 (3.7.3-4ubuntu1.7) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../libseccomp2_2.5.3-2ubuntu3~22.04.1_amd64.deb ...\n",
            "Unpacking libseccomp2:amd64 (2.5.3-2ubuntu3~22.04.1) over (2.5.3-2ubuntu2) ...\n",
            "Setting up libseccomp2:amd64 (2.5.3-2ubuntu3~22.04.1) ...\n",
            "(Reading database ... 126498 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libss2_1.46.5-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking libss2:amd64 (1.46.5-2ubuntu1.2) over (1.46.5-2ubuntu1.1) ...\n",
            "Preparing to unpack .../01-openssl_3.0.2-0ubuntu1.19_amd64.deb ...\n",
            "Unpacking openssl (3.0.2-0ubuntu1.19) over (3.0.2-0ubuntu1.16) ...\n",
            "Preparing to unpack .../02-libctf0_2.38-4ubuntu2.8_amd64.deb ...\n",
            "Unpacking libctf0:amd64 (2.38-4ubuntu2.8) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../03-libctf-nobfd0_2.38-4ubuntu2.8_amd64.deb ...\n",
            "Unpacking libctf-nobfd0:amd64 (2.38-4ubuntu2.8) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../04-binutils-x86-64-linux-gnu_2.38-4ubuntu2.8_amd64.deb ...\n",
            "Unpacking binutils-x86-64-linux-gnu (2.38-4ubuntu2.8) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../05-libbinutils_2.38-4ubuntu2.8_amd64.deb ...\n",
            "Unpacking libbinutils:amd64 (2.38-4ubuntu2.8) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../06-binutils_2.38-4ubuntu2.8_amd64.deb ...\n",
            "Unpacking binutils (2.38-4ubuntu2.8) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../07-binutils-common_2.38-4ubuntu2.8_amd64.deb ...\n",
            "Unpacking binutils-common:amd64 (2.38-4ubuntu2.8) over (2.38-4ubuntu2.6) ...\n",
            "Preparing to unpack .../08-cuda-toolkit-12-config-common_12.9.79-1_all.deb ...\n",
            "Unpacking cuda-toolkit-12-config-common (12.9.79-1) over (12.5.82-1) ...\n",
            "Preparing to unpack .../09-cuda-toolkit-config-common_13.0.88-1_all.deb ...\n",
            "Unpacking cuda-toolkit-config-common (13.0.88-1) over (12.5.82-1) ...\n",
            "Preparing to unpack .../10-dpkg-dev_1.21.1ubuntu2.6_all.deb ...\n",
            "Unpacking dpkg-dev (1.21.1ubuntu2.6) over (1.21.1ubuntu2.3) ...\n",
            "Preparing to unpack .../11-libdpkg-perl_1.21.1ubuntu2.6_all.deb ...\n",
            "Unpacking libdpkg-perl (1.21.1ubuntu2.6) over (1.21.1ubuntu2.3) ...\n",
            "Preparing to unpack .../12-libldap-2.5-0_2.5.19+dfsg-0ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libldap-2.5-0:amd64 (2.5.19+dfsg-0ubuntu0.22.04.1) over (2.5.17+dfsg-0ubuntu0.22.04.1) ...\n",
            "Preparing to unpack .../13-linux-libc-dev_5.15.0-156.166_amd64.deb ...\n",
            "Unpacking linux-libc-dev:amd64 (5.15.0-156.166) over (5.15.0-113.123) ...\n",
            "Preparing to unpack .../14-python3-pkg-resources_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-pkg-resources (68.1.2-2~jammy3) over (59.6.0-1.2ubuntu0.22.04.3) ...\n",
            "Setting up python3-pkg-resources (68.1.2-2~jammy3) ...\n",
            "Setting up cuda-toolkit-config-common (13.0.88-1) ...\n",
            "Setting up binutils-common:amd64 (2.38-4ubuntu2.8) ...\n",
            "Setting up linux-libc-dev:amd64 (5.15.0-156.166) ...\n",
            "Setting up libctf-nobfd0:amd64 (2.38-4ubuntu2.8) ...\n",
            "Setting up perl-modules-5.34 (5.34.0-3ubuntu1.5) ...\n",
            "Setting up libldap-2.5-0:amd64 (2.5.19+dfsg-0ubuntu0.22.04.1) ...\n",
            "Setting up libss2:amd64 (1.46.5-2ubuntu1.2) ...\n",
            "Setting up logsave (1.46.5-2ubuntu1.2) ...\n",
            "Setting up libbinutils:amd64 (2.38-4ubuntu2.8) ...\n",
            "Setting up openssl (3.0.2-0ubuntu1.19) ...\n",
            "Setting up cuda-toolkit-12-config-common (12.9.79-1) ...\n",
            "Setting up libctf0:amd64 (2.38-4ubuntu2.8) ...\n",
            "Setting up libperl5.34:amd64 (5.34.0-3ubuntu1.5) ...\n",
            "Setting up e2fsprogs (1.46.5-2ubuntu1.2) ...\n",
            "Setting up perl (5.34.0-3ubuntu1.5) ...\n",
            "Setting up libdpkg-perl (1.21.1ubuntu2.6) ...\n",
            "Setting up binutils-x86-64-linux-gnu (2.38-4ubuntu2.8) ...\n",
            "Setting up binutils (2.38-4ubuntu2.8) ...\n",
            "Setting up dpkg-dev (1.21.1ubuntu2.6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "d_j7nNbKRmhx",
        "outputId": "e249d2bb-73f2-4d60-a1f9-1a07381a115d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libarchive-dev:amd64.\n",
            "(Reading database ... 126441 files and directories currently installed.)\n",
            "Preparing to unpack .../libarchive-dev_3.6.0-1ubuntu1.5_amd64.deb ...\n",
            "Unpacking libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Setting up libarchive-dev:amd64 (3.6.0-1ubuntu1.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting libarchive\n",
            "  Downloading libarchive-0.4.7.tar.gz (23 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nose (from libarchive)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: libarchive\n",
            "  Building wheel for libarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libarchive: filename=libarchive-0.4.7-py3-none-any.whl size=31629 sha256=5498f0ee068c6123f01425c24c03227e72dae1741dd55cdb848bf7f887a9d021\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/20/ab/f101da7b245b996aa097685ef742243725ea6150f5b3b6d9ed\n",
            "Successfully built libarchive\n",
            "Installing collected packages: nose, libarchive\n",
            "Successfully installed libarchive-0.4.7 nose-1.3.7\n"
          ]
        }
      ],
      "source": [
        "# https://pypi.python.org/pypi/libarchive\n",
        "!apt-get -qq install -y libarchive-dev && pip install -U libarchive\n",
        "import libarchive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w9llCG2wSRDx",
        "outputId": "d17b3899-354a-430f-aee0-0eb8d49b1838",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.12/dist-packages (from pydot) (3.2.4)\n"
          ]
        }
      ],
      "source": [
        "# https://pypi.python.org/pypi/pydot\n",
        "!apt-get -qq install -y graphviz && pip install pydot\n",
        "import pydot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Zq68DSY2rP2W",
        "outputId": "810bcb66-ac1d-4296-9e9e-58e13558ccf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cartopy\n",
            "  Downloading cartopy-0.25.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from cartopy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.12/dist-packages (from cartopy) (3.10.0)\n",
            "Requirement already satisfied: shapely>=2.0 in /usr/local/lib/python3.12/dist-packages (from cartopy) (2.1.1)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from cartopy) (25.0)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.12/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.12/dist-packages (from cartopy) (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6->cartopy) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from pyproj>=3.3.1->cartopy) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->cartopy) (1.17.0)\n",
            "Downloading cartopy-0.25.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cartopy\n",
            "Successfully installed cartopy-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cartopy\n",
        "import cartopy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Import thư viện</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "n2ZRXglT_5Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "from torchmetrics.segmentation import DiceScore\n",
        "from torchmetrics import  JaccardIndex\n",
        "import segmentation_models_pytorch as smp\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2 # np.array -> torch.tensor\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "qCnMyzJgZqJr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mask_path = \"/content/annotations/trimaps/Abyssinian_1.png\"\n",
        "# mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "# plt.imshow(mask)\n",
        "# print(np.unique(mask))"
      ],
      "metadata": {
        "id": "BflMgDcZbPIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image_path = \"/content/images/Abyssinian_10.jpg\"\n",
        "# image = cv2.imread(image_path)\n",
        "# image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "# plt.imshow(image)\n",
        "# print(image.shape)"
      ],
      "metadata": {
        "id": "Ocq9MrPtcA5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Định nghĩa Dataset</h3>\n",
        "</div>\n",
        "Viết class kế thừa từ class Dataset cung cấp sẵn trong PyTorch để đọc dữ liệu từ ổ cứng. Yêu cầu viết đủ 3 hàm __init__() để khởi tạo class, __len__() để trả về số điểm dữ liệu có trong tập dữ liệu và __getitem__() trả về 1 điểm dữ liệu cụ thể"
      ],
      "metadata": {
        "id": "Xz7v36fKCFqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DogCatDataset(Dataset):\n",
        "    def __init__(self, root_dir, txt_file, transform=None): #transform: augmentation + norm + np.array -> torch.tensor\n",
        "        super().__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.txt_file = txt_file\n",
        "        self.transform = transform\n",
        "        self.img_path_lst = []\n",
        "        with open(self.txt_file) as file_in:\n",
        "            for line in file_in:\n",
        "                self.img_path_lst.append(line.split(\" \")[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path_lst)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.root_dir, \"images\", \"{}.jpg\".format(self.img_path_lst[idx]))\n",
        "        mask_path = os.path.join(self.root_dir, \"annotations\", \"trimaps\", \"{}.png\".format(self.img_path_lst[idx]))\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        # foreground -> 1\n",
        "        # background 2 -> 0\n",
        "        # 3 -> 1\n",
        "        mask[mask == 2] = 0\n",
        "        mask[mask == 3] = 1\n",
        "        # image (RGB), mask (2D matrix)\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            transformed_image = transformed['image']\n",
        "            transformed_mask = transformed['mask']\n",
        "        return transformed_image, transformed_mask"
      ],
      "metadata": {
        "id": "GNv3AOficqQK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Định nghĩa các phép augmentation trên ảnh</h3>\n",
        "</div>\n",
        "Sử dụng thư viện Albumentations, tham khảo thêm: https://albumentations.ai/docs/api_reference/full_reference/"
      ],
      "metadata": {
        "id": "en9W5v_xChlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainsize = 384\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.Resize(width=trainsize, height=trainsize),\n",
        "    A.HorizontalFlip(),\n",
        "    A.RandomBrightnessContrast(),\n",
        "    A.Blur(),\n",
        "    A.Sharpen(),\n",
        "    A.RGBShift(),\n",
        "    A.Cutout(num_holes=5, max_h_size=25, max_w_size=25, fill_value=0),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_trainsform = A.Compose([\n",
        "    A.Resize(width=trainsize, height=trainsize),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "    ToTensorV2(), # numpy.array -> torch.tensor (B, 3, H, W)\n",
        "])"
      ],
      "metadata": {
        "id": "e4RPW6nMgx4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "c7ac53cf-24b7-4630-a519-52a0bf53cbe0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'albumentations' has no attribute 'Cutout'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-350760384.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRGBShift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCutout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_holes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_h_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_w_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_pixel_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mToTensorV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'Cutout'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Đoạn code dùng để convert ảnh sau khi đã chuẩn hoá thành ảnh ban đầu</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "r81wtP0PCzUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor\n",
        "\n",
        "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
      ],
      "metadata": {
        "id": "RSdnanKkjlD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Kiểm tra 1 cặp ảnh đầu vào và ảnh kết quả phân vùng trước khi đưa vào mô hình training</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "x_CbSVe6C_bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = DogCatDataset(\"/content\", \"/content/annotations/trainval.txt\", train_transform)\n",
        "test_dataset = DogCatDataset(\"/content\", \"/content/annotations/test.txt\", test_trainsform)\n",
        "\n",
        "image, mask = train_dataset.__getitem__(10)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(unorm(image).permute(1, 2, 0))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(mask)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "06Kt7pRTfD8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Lập trình mô hình UNet cơ bản</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "XNubRiEKDHg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model UNet\n",
        "def unet_block(in_channels, out_channels):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, 1, 1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, 3, 1, 1),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.n_classes = n_classes\n",
        "        self.downsample = nn.MaxPool2d(2)\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
        "        self.block_down1 = unet_block(3, 64)\n",
        "        self.block_down2 = unet_block(64, 128)\n",
        "        self.block_down3 = unet_block(128, 256)\n",
        "        self.block_down4 = unet_block(256, 512)\n",
        "        self.block_neck = unet_block(512, 1024)\n",
        "        self.block_up1 = unet_block(1024+512, 512)\n",
        "        self.block_up2 = unet_block(256+512, 256)\n",
        "        self.block_up3 = unet_block(128+256, 128)\n",
        "        self.block_up4 = unet_block(128+64, 64)\n",
        "        self.conv_cls = nn.Conv2d(64, self.n_classes, 1) # -> (B, n_class, H, W)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (B, C, H, W)\n",
        "        x1 = self.block_down1(x)\n",
        "        x = self.downsample(x1)\n",
        "        x2 = self.block_down2(x)\n",
        "        x = self.downsample(x2)\n",
        "        x3 = self.block_down3(x)\n",
        "        x = self.downsample(x3)\n",
        "        x4 = self.block_down4(x)\n",
        "        x = self.downsample(x4)\n",
        "\n",
        "        x = self.block_neck(x)\n",
        "\n",
        "        x = torch.cat([x4, self.upsample(x)], dim=1)\n",
        "        x = self.block_up1(x)\n",
        "        x = torch.cat([x3, self.upsample(x)], dim=1)\n",
        "        x = self.block_up2(x)\n",
        "        x = torch.cat([x2, self.upsample(x)], dim=1)\n",
        "        x = self.block_up3(x)\n",
        "        x = torch.cat([x1, self.upsample(x)], dim=1)\n",
        "        x = self.block_up4(x)\n",
        "\n",
        "        x = self.conv_cls(x)\n",
        "        return x\n",
        "\n",
        "# model = UNet(1)\n",
        "# x = torch.rand(4, 3, trainsize, trainsize)\n",
        "# print(\"Input shape =\", x.shape)\n",
        "# y = model(x).squeeze()\n",
        "# print(\"Output shape = \", y.shape)\n",
        "# # y true (4, 384, 384)\n",
        "# # y hat.squeeze() (4, 1, 384, 384) -> (4, 384, 384)"
      ],
      "metadata": {
        "id": "3nSSXeMMmXy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Tạo AverageMeter</h3>\n",
        "</div>\n",
        "AverageMeter có nhiệm vụ lưu lại giá trị trung bình của độ chính xác, giá trị hàm loss, ... trong suốt quá trình training. Tham khảo thêm: https://discuss.pytorch.org/t/meaning-of-parameters/10655"
      ],
      "metadata": {
        "id": "-OZbtvpnD1ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "OJ0zgMSXy-7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Lập trình hàm tính toán độ chính xác</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "s8u9IBDlEQyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy fn\n",
        "def accuracy_function(preds, targets):\n",
        "    preds_flat = preds.flatten()\n",
        "    targets_flat = targets.flatten()\n",
        "    acc = torch.sum(preds_flat == targets_flat)\n",
        "    return acc/targets_flat.shape[0]"
      ],
      "metadata": {
        "id": "9S0zUD210VJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Chuẩn bị cho quá trình training</h3>\n",
        "</div>\n",
        "\n",
        "\n",
        "1.   Lựa chọn device: PyTorch yêu cầu lựa chọn cụ thể device sẽ train và yêu cầu người dùng tự move dữ liệu, mô hình vào device đã lựa chọn. Device có thể là \"cuda\" - tức là GPU NVIDIA hoặc \"cpu\".\n",
        "2.   Định nghĩa DataLoader, khác với Dataset là cách đọc dữ liệu từ ổ cứng, DataLoader ghép nhiều điểm dữ liệu vào cùng nhau tạo thành 1 batch để đưa vào train mô hình. Lưu ý thêm: batch_size nên đặt là 4, 8, 16, 32, ... và nên để lớn nhất có thể\n",
        "3.   Khởi tạo mô hình\n",
        "4.   Khởi tạo hàm loss\n",
        "5.   Khởi tạo thuật toán tối ưu (optimizer)\n",
        "6.   Khởi tạo các độ đo sẽ sử dụng để đánh giá hiệu năng của mô hình. Phần này sẽ sử dụng các hàm độ đo Dice và IoU được lập trình sẵn trong thư viện torchmetrics\n",
        "7.   Khởi tạo từng AverageMeter để lưu lại giá trị của từng độ đo, giá trị hàm loss, thời gian train, ... trong suốt quá trình train\n",
        "\n"
      ],
      "metadata": {
        "id": "MxkzTm38EXCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#load data\n",
        "batch_size = 8\n",
        "n_workers = os.cpu_count()\n",
        "print(\"num_workers =\", n_workers)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=n_workers)\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=n_workers)\n",
        "\n",
        "#model\n",
        "model = UNet(1).to(device)\n",
        "\n",
        "#loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "n_eps = 30\n",
        "\n",
        "#metrics\n",
        "dice_fn = torchmetrics.Dice(num_classes=2, average=\"macro\").to(device)\n",
        "iou_fn = torchmetrics.JaccardIndex(num_classes=2, task=\"binary\", average=\"macro\").to(device)\n",
        "\n",
        "#meter\n",
        "acc_meter = AverageMeter()\n",
        "train_loss_meter = AverageMeter()\n",
        "dice_meter = AverageMeter()\n",
        "iou_meter = AverageMeter()"
      ],
      "metadata": {
        "id": "xldeI02fubce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Training thôi ...</h3>\n",
        "</div>\n",
        "Tham khảo thêm cách viết code training trong PyTorch: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ],
      "metadata": {
        "id": "-vf73-nLFrkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ep in range(1, 1+n_eps):\n",
        "    acc_meter.reset()\n",
        "    train_loss_meter.reset()\n",
        "    dice_meter.reset()\n",
        "    iou_meter.reset()\n",
        "    model.train()\n",
        "\n",
        "    for batch_id, (x, y) in enumerate(tqdm(trainloader), start=1):\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).float()\n",
        "        y_hat = model(x)\n",
        "        y_hat = y_hat.squeeze() # -> logit (-vc, +vc)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_hat_mask = y_hat.sigmoid().round().long() # -> mask (0, 1)\n",
        "            dice_score = dice_fn(y_hat_mask, y.long())\n",
        "            iou_score = iou_fn(y_hat_mask, y.long())\n",
        "            accuracy = accuracy_function(y_hat_mask, y.long())\n",
        "\n",
        "            train_loss_meter.update(loss.item(), n)\n",
        "            iou_meter.update(iou_score.item(), n)\n",
        "            dice_meter.update(dice_score.item(), n)\n",
        "            acc_meter.update(accuracy.item(), n)\n",
        "\n",
        "    print(\"EP {}, train loss = {}, accuracy = {}, IoU = {}, dice = {}\".format(\n",
        "        ep, train_loss_meter.avg, acc_meter.avg, iou_meter.avg, dice_meter.avg\n",
        "    ))\n",
        "    if ep >= 25:\n",
        "        torch.save(model.state_dict(), \"/content/model_ep_{}.pth\".format(ep))"
      ],
      "metadata": {
        "id": "iyoAzYen1G3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Viết code đưa ra kết quả trên tập dữ liệu test</h3>\n",
        "</div>\n",
        "Lưu ý: Trong quá trình test cần chuyển model về chế độ eval và nên đặt torch.no_grad(). Điểm khác nhau giữa model.eval() và torch.no_grad() là model.eval() sẽ đặt chế độ của mô hình về chế độ evaluation (thay đổi các layer như dropout, batch norm, ... khác với quá trình training) còn torch.no_grad() sẽ tắt tính toán đạo hàm của PyTorch để tiết kiệm tính toán. Do vậy khi test mô hình nên chú ý dùng cả 2 câu lệnh này."
      ],
      "metadata": {
        "id": "Xlx3dVD9I_K8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_iou_meter = AverageMeter()\n",
        "test_dice_meter = AverageMeter()\n",
        "with torch.no_grad():\n",
        "    for batch_id, (x, y) in enumerate(tqdm(testloader), start=1):\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).float()\n",
        "        y_hat = model(x)\n",
        "        y_hat = y_hat.squeeze()\n",
        "        y_hat_mask = y_hat.sigmoid().round().long()\n",
        "        dice_score = dice_fn(y_hat_mask, y.long())\n",
        "        iou_score = iou_fn(y_hat_mask, y.long())\n",
        "        test_dice_meter.update(dice_score.item(), n)\n",
        "        test_iou_meter.update(iou_score.item(), n)\n",
        "print(\"TEST: IoU = {}, dice = {}\".format(test_iou_meter.avg, test_dice_meter.avg))"
      ],
      "metadata": {
        "id": "WY4wUsAb5CZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"markdown-google-sans\">\n",
        "  <h3>Viết code hiển thị kết quả dự đoán</h3>\n",
        "</div>"
      ],
      "metadata": {
        "id": "OdAA1WJJKGir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "model.eval()\n",
        "idx = random.randint(0, 100)\n",
        "with torch.no_grad():\n",
        "    x, y = test_dataset[idx]\n",
        "    # print(x.shape, y.shape) (C, H, W) -> (1, C, H, W) -> model\n",
        "    x = x.to(device).float().unsqueeze(0)\n",
        "    y_hat = model(x).squeeze() #(1, 1, H, W) -> (H, W)\n",
        "    y_hat_mask = y_hat.sigmoid().round().long()\n",
        "    # x, y, y_hat_mask\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(unorm(x.squeeze().cpu()).permute(1, 2, 0)) # x (GPU) -> x(CPU)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(y)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(y_hat_mask.cpu())"
      ],
      "metadata": {
        "id": "EBIp2CbXKFGH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}